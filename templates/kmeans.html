spectral
heirarchical


#clustering
#note, in Number of Cluster: you need to put some pointer that fills it in with the K chosen...

<p>K-Means Clustering: a clustering technique which assigns observations to clusters based on distance from the cluster center. Observations are assigned to the cluster whose center is the shortest distance from the observation. Clusters are chosen which minimize the distance from each observation to it's cluster's center</p>
<p>Algorithm: Start with k random points, treat these as the cluster centers. Assign each observation a cluster. Recompute cluster centers and reassign observations. Repeat until total distance from centers stops changing and record results. Repeat whole process N times, and select result with lowest sum of distances from centers.</p>
<p>Model Paramters</p>
<p>Distance Measure: Euclidean</p>
<p>Center: Mean</p>
<p>Number of Clusters: whatever K is</p>
<p>Algorithm Parameters</p>
<p>Number of Iterations(N): 300</p>


#heirarchical

<p>Agglomerative Heirarchical Clustering: a clustering technique which uses a tree structure to assign clusters. A representational tree is computed where the bottom nodes of the tree are the observations as (treated as single member clusters) and the height of the tree represents distance. At the distance between individual clusters, branches merge to form new clusters. Unlike K-Means and

    Distance between clusters is calculated using a linkage function, and at the distance between clusters, the branches of the tree join into a single cluster. </p>